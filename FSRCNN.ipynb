{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtdGfTlCc6Lv"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons\n",
        "!pip install tensorflow==2.11.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF-oZwtT4Jl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fc3452-cbf3-4426-dd77-693b56df2d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, PReLU, ZeroPadding2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sM7vbYQdFuU",
        "outputId": "fa4bb529-025a-48c1-b900-1b277c6cb04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ7JpopsBrot"
      },
      "source": [
        "### Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEW6nKLWWBvi"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/SRCNN/Train'\n",
        "TEST_DIR = '/content/drive/MyDrive/SRCNN/Test/Set5'\n",
        "VAL_DIR = '/content/drive/MyDrive/SRCNN/Test/Set14'\n",
        "SCALE = 3\n",
        "SIZE_INPUT = 7\n",
        "SIZE_LABEL = 21\n",
        "STRIDE = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NugpbR3YB9YK"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation():\n",
        "    all_files = os.listdir(TRAIN_DIR)    \n",
        "    for file in all_files:\n",
        "        img = cv2.imread(os.path.join(TRAIN_DIR, file))\n",
        "        for scale in [0.9, 0.8, 0.7, 0.6]:\n",
        "            h, w, _ = img.shape\n",
        "            new_img = tf.image.resize(img, (int(h*scale), int(w*scale)), method='bicubic', preserve_aspect_ratio=True)\n",
        "            new_img = np.array(new_img)\n",
        "            for rotate in [90, 180, 270]:\n",
        "                new_img = cv2.rotate(new_img, cv2.ROTATE_90_CLOCKWISE)\n",
        "                path = file[:-3]+'0'+str(int(scale*10))+'.'+str(rotate)+'.bmp'\n",
        "                cv2.imwrite(path, new_img)"
      ],
      "metadata": {
        "id": "60qgYhwFyCJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZUWCRowfpfu"
      },
      "outputs": [],
      "source": [
        "def crop(image, factor):\n",
        "    # ensure no remainder while scaling\n",
        "\n",
        "    size = image.shape\n",
        "    size -= np.array(np.mod(size, factor), dtype=np.uint8)\n",
        "    image = image[:size[0], :size[1], :]\n",
        "    return image\n",
        "\n",
        "def generator(data_path):\n",
        "    files = os.listdir(data_path)\n",
        "    def img_gen():\n",
        "        for file in files:\n",
        "            path = os.path.join(data_path, file)\n",
        "            img_arr = np.array(Image.open(path), dtype=np.uint8)\n",
        "            img_arr = np.array(cv2.cvtColor(np.array(img_arr), cv2.COLOR_RGB2YCrCb), dtype=float)\n",
        "            img_label = tf.expand_dims(crop(img_arr, SCALE)[:,:,0], axis=-1)\n",
        "            h, w, _ = img_label.shape\n",
        "\n",
        "            down_sample = tf.image.resize(img_label, (int(h/SCALE), int(w/SCALE)), method='bicubic')\n",
        "\n",
        "            h, w, _ = down_sample.shape\n",
        "            \n",
        "            xlabel = 0   \n",
        "            for x in range(0, h-SIZE_INPUT+1, STRIDE):\n",
        "                ylabel = 0\n",
        "                for y in range(0, w-SIZE_INPUT+1, STRIDE):\n",
        "                    sub_img_input = down_sample[x:x+SIZE_INPUT, y:y+SIZE_INPUT]\n",
        "                    sub_img_label = img_label[xlabel:xlabel+SIZE_LABEL, ylabel:ylabel+SIZE_LABEL]\n",
        "                    ylabel += SCALE * STRIDE\n",
        "\n",
        "                    yield (sub_img_input, sub_img_label)\n",
        "\n",
        "                xlabel += SCALE * STRIDE\n",
        "\n",
        "    return img_gen\n",
        "\n",
        "def create_dataset(path):\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        generator(path),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(SIZE_INPUT, SIZE_INPUT, 1),),\n",
        "            tf.TensorSpec(shape=(SIZE_LABEL, SIZE_LABEL, 1),)\n",
        "        )\n",
        "    )\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PSNR(y_true, y_pred):\n",
        "\tmax_pixel = 255.0\n",
        "\treturn 10.0 * tf_log10((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true)))) "
      ],
      "metadata": {
        "id": "Xgv2IaEIjWWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation()"
      ],
      "metadata": {
        "id": "8agonYIq9oKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4gUYw9aUv9H"
      },
      "outputs": [],
      "source": [
        "train = create_dataset(TRAIN_DIR).shuffle(600000).batch(256)\n",
        "val = create_dataset(VAL_DIR).shuffle(1000).batch(256)\n",
        "# test = create_dataset(TEST_DIR).shuffle(1000).batch(256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blSXmQ4YBt1c"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMDcZ5YxD2vv"
      },
      "outputs": [],
      "source": [
        "def create_model(d=56, s=12, m=4): # 5-1-3\n",
        "    input = Input(shape = (SIZE_INPUT, SIZE_INPUT, 1))\n",
        "    x = Conv2D(d, 5, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.001), padding='same')(input)\n",
        "    x = PReLU()(x)\n",
        "    x = Conv2D(s, 1, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.001), padding='same')(x)\n",
        "    x = PReLU()(x)\n",
        "    for i in range(m):\n",
        "        x = Conv2D(s, 3, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.001), padding='same')(x)\n",
        "    x = PReLU()(x)\n",
        "    x = Conv2D(d, 1, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.001), padding='same')(x)\n",
        "    x = PReLU()(x)\n",
        "    output = Conv2DTranspose(1, 9, strides=SCALE, padding='same')(x)\n",
        "    model = tf.keras.Model(inputs = input,\n",
        "                           outputs = output)\n",
        "\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sTLpmdlEgIIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f745b697-0a3d-4779-f06a-4a355eebc646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 7, 7, 1)]         0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 7, 7, 56)          1456      \n",
            "                                                                 \n",
            " p_re_lu_12 (PReLU)          (None, 7, 7, 56)          2744      \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 7, 7, 12)          684       \n",
            "                                                                 \n",
            " p_re_lu_13 (PReLU)          (None, 7, 7, 12)          588       \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 7, 7, 12)          1308      \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 7, 7, 12)          1308      \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 7, 7, 12)          1308      \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 7, 7, 12)          1308      \n",
            "                                                                 \n",
            " p_re_lu_14 (PReLU)          (None, 7, 7, 12)          588       \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 7, 7, 56)          728       \n",
            "                                                                 \n",
            " p_re_lu_15 (PReLU)          (None, 7, 7, 56)          2744      \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 21, 21, 1)        4537      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,301\n",
            "Trainable params: 19,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruUe4bjTbA0V"
      },
      "outputs": [],
      "source": [
        "# save the model with min val_loss\n",
        "file_path = \"/content/drive/MyDrive/SRCNN/saved_model/fsrcnn.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train on 91"
      ],
      "metadata": {
        "id": "qzFrgjNugbcw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8_BgpU1BRxr"
      },
      "outputs": [],
      "source": [
        "optimizers = [\n",
        "    tf.keras.optimizers.Adam(learning_rate = 1e-3),\n",
        "    tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
        "]\n",
        "optimizers_and_layers = [(optimizers[0], model.layers[:-1]), (optimizers[1], model.layers[-1])]\n",
        "optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    # optimizer=tf.keras.optimizers.SGD(learning_rate = 1e-4),\n",
        "    loss=\"mse\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvO9P50bcwiv"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    train,\n",
        "    epochs = 80,\n",
        "    validation_data = val,\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor = 'val_loss', patience=5),\n",
        "        checkpoint,]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine tune on 100"
      ],
      "metadata": {
        "id": "TJvDHRuqgYCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = [\n",
        "    tf.keras.optimizers.SGD(learning_rate = 1e-6),\n",
        "    tf.keras.optimizers.SGD(learning_rate = 1e-8)\n",
        "]\n",
        "optimizers_and_layers = [(optimizers[0], model.layers[:-1]), (optimizers[1], model.layers[-1])]\n",
        "optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
        "m.compile(\n",
        "    optimizer=optimizer,\n",
        "    # optimizer=tf.keras.optimizers.SGD(learning_rate = 1e-4),\n",
        "    loss=\"mse\"\n",
        ")\n",
        "m.fit(\n",
        "    train,\n",
        "    epochs = 80000,\n",
        "    validation_data = val,\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor = 'val_loss', patience=5),\n",
        "        checkpoint,]\n",
        ")"
      ],
      "metadata": {
        "id": "vYBZ2DQFgOr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCobJTwk2n7_"
      },
      "source": [
        "### Test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQMgPVxpd8up"
      },
      "outputs": [],
      "source": [
        "def merge(path_ori, srcnn, scale):\n",
        "    img_arr = np.array(Image.open(path_ori), dtype=np.uint8)\n",
        "    img_arr = np.array(cv2.cvtColor(np.array(img_arr), cv2.COLOR_RGB2YCrCb), dtype=float)\n",
        "    y_channel = img_arr[:,:,0]\n",
        "    img_ori = tf.expand_dims(crop(y_channel, scale), axis=-1)\n",
        "    h, w, _ = img_ori.shape\n",
        "\n",
        "    down_sample = tf.image.resize(img_ori, (int(h/scale), int(w/scale)), method='bicubic')\n",
        "\n",
        "    img_input = tf.image.resize(down_sample, (h, w), method='bicubic')\n",
        "    patches = []\n",
        "    col = 0\n",
        "    for x in range(0, h-SIZE_INPUT+1, SIZE_LABEL):\n",
        "        row = 0\n",
        "        for y in range(0, w-SIZE_INPUT+1, SIZE_LABEL):\n",
        "            sub_img_input = img_input[x:x+SIZE_INPUT, y:y+SIZE_INPUT]\n",
        "            patches.append(sub_img_input)\n",
        "            row += 1\n",
        "        col += 1\n",
        "    img_in = tf.convert_to_tensor(patches)\n",
        "\n",
        "    res = srcnn.predict(img_in)\n",
        "    img_sr = np.zeros((col*SIZE_LABEL, row*SIZE_LABEL, 1))\n",
        "    print(img_sr.shape)\n",
        "    for i in range(len(res)):\n",
        "        r = i % row\n",
        "        c = i // row\n",
        "        img_sr[c*SIZE_LABEL:(c+1)*SIZE_LABEL, r*SIZE_LABEL:(r+1)*SIZE_LABEL, :] = res[i]\n",
        "\n",
        "    return img_ori, img_input, img_sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79MVcaWKEUwe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtdGfTlCc6Lv"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons\n",
        "!pip install tensorflow==2.11.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF-oZwtT4Jl2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sM7vbYQdFuU",
        "outputId": "f8507923-8c5d-4512-9d09-cd20d783e909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ7JpopsBrot"
      },
      "source": [
        "### Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEW6nKLWWBvi"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/SRCNN/Train'\n",
        "TEST_DIR = '/content/drive/MyDrive/SRCNN/Test/Set5'\n",
        "VAL_DIR = '/content/drive/MyDrive/SRCNN/Test/Set14'\n",
        "SCALE = 3\n",
        "SIZE_INPUT = 33\n",
        "SIZE_LABEL = 21 # test_stride always equal size_label for patches to be consective\n",
        "PAD = int(abs(SIZE_INPUT - SIZE_LABEL)/2)\n",
        "STRIDE = 14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NugpbR3YB9YK"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZUWCRowfpfu"
      },
      "outputs": [],
      "source": [
        "def crop(image, factor):\n",
        "    # ensure no remainder while scaling\n",
        "\n",
        "    size = image.shape\n",
        "    size -= np.mod(size, factor)\n",
        "    image = image[:size[0], :size[1]]\n",
        "    return image\n",
        "\n",
        "def generator(data_path):\n",
        "    files = os.listdir(data_path)\n",
        "    def img_gen():\n",
        "        for file in files:\n",
        "            path = os.path.join(data_path, file)\n",
        "            img_arr = np.array(Image.open(path), dtype=np.uint8)\n",
        "            img_arr = np.array(cv2.cvtColor(np.array(img_arr), cv2.COLOR_RGB2YCrCb), dtype=float)\n",
        "            y_channel = img_arr[:,:,0]\n",
        "            img_label = tf.expand_dims(crop(y_channel, SCALE), axis=-1)\n",
        "            h, w, _ = img_label.shape\n",
        "\n",
        "            down_sample = tf.image.resize(img_label, (int(h/SCALE), int(w/SCALE)), method='bicubic')\n",
        "            img_input = tf.image.resize(down_sample, (h, w), method='bicubic')\n",
        "            \n",
        "            for x in range(0, h-SIZE_INPUT+1, STRIDE):\n",
        "                for y in range(0, w-SIZE_INPUT+1, STRIDE):\n",
        "                    sub_img_input = img_input[x:x+SIZE_INPUT, y:y+SIZE_INPUT]\n",
        "                    sub_img_label = img_label[x+PAD:x+PAD+SIZE_LABEL, y+PAD:y+PAD+SIZE_LABEL]\n",
        "\n",
        "                    yield (sub_img_input, sub_img_label)\n",
        "    return img_gen\n",
        "\n",
        "def create_dataset(path):\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        generator(path),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(SIZE_INPUT, SIZE_INPUT, 1),),\n",
        "            tf.TensorSpec(shape=(SIZE_LABEL, SIZE_LABEL, 1),)\n",
        "        )\n",
        "    )\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9O2zAS-kN1G"
      },
      "outputs": [],
      "source": [
        "def merge(path_ori, srcnn, scale):\n",
        "    img_arr = np.array(Image.open(path_ori), dtype=np.uint8)\n",
        "    img_arr = np.array(cv2.cvtColor(np.array(img_arr), cv2.COLOR_RGB2YCrCb), dtype=float)\n",
        "    y_channel = img_arr[:,:,0]\n",
        "    img_ori = tf.expand_dims(crop(y_channel, scale), axis=-1)\n",
        "    h, w, _ = img_ori.shape\n",
        "\n",
        "    down_sample = tf.image.resize(img_ori, (int(h/scale), int(w/scale)), method='bicubic')\n",
        "\n",
        "    img_input = tf.image.resize(down_sample, (h, w), method='bicubic')\n",
        "    patches = []\n",
        "    col = 0\n",
        "    for x in range(0, h-SIZE_INPUT+1, SIZE_LABEL):\n",
        "        row = 0\n",
        "        for y in range(0, w-SIZE_INPUT+1, SIZE_LABEL):\n",
        "            sub_img_input = img_input[x:x+SIZE_INPUT, y:y+SIZE_INPUT]\n",
        "            patches.append(sub_img_input)\n",
        "            row += 1\n",
        "        col += 1\n",
        "    img_in = tf.convert_to_tensor(patches)\n",
        "\n",
        "    res = srcnn.predict(img_in)\n",
        "    img_sr = np.zeros((col*SIZE_LABEL, row*SIZE_LABEL, 1))\n",
        "    for i in range(len(res)):\n",
        "        r = i % row\n",
        "        c = i // row\n",
        "        img_sr[c*SIZE_LABEL:(c+1)*SIZE_LABEL, r*SIZE_LABEL:(r+1)*SIZE_LABEL, :] = res[i]\n",
        "\n",
        "    return img_ori, img_input, img_sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4gUYw9aUv9H"
      },
      "outputs": [],
      "source": [
        "train = create_dataset(TRAIN_DIR).shuffle(30000).batch(256)\n",
        "val = create_dataset(VAL_DIR).shuffle(1000).batch(256)\n",
        "# test = create_dataset(TEST_DIR).shuffle(1000).batch(256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blSXmQ4YBt1c"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMDcZ5YxD2vv"
      },
      "outputs": [],
      "source": [
        "def create_model(f1=9, f2=1, f3=5, n1=64, n2=32):\n",
        "    model = tf.keras.Sequential([\n",
        "        Input(shape = (SIZE_INPUT, SIZE_INPUT, 1)),\n",
        "        Conv2D(n1, f1, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.001)),\n",
        "        Conv2D(n2, f2, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.001)),\n",
        "        Conv2D(1, f3, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.001))\n",
        "    ])\n",
        "\n",
        "    optimizers = [\n",
        "        tf.keras.optimizers.SGD(learning_rate = 1e-4),\n",
        "        tf.keras.optimizers.SGD(learning_rate = 1e-5)\n",
        "    ]\n",
        "    optimizers_and_layers = [(optimizers[0], model.layers[:2]), (optimizers[1], model.layers[2])]\n",
        "    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        # optimizer=tf.keras.optimizers.SGD(learning_rate = 1e-4),\n",
        "        loss=\"mse\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8_BgpU1BRxr",
        "outputId": "e406f37d-65f3-4d1c-c831-215e5b70b10b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 64)        5248      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 32)        2080      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 21, 21, 1)         801       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,129\n",
            "Trainable params: 8,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "m = create_model(f1=9, f2=1, f3=5, n1=64, n2=32)\n",
        "m.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty97QLQJfoi3"
      },
      "outputs": [],
      "source": [
        "# https://www.mathworks.com/matlabcentral/answers/127891-x-0-0-1-10-what-s-going-on-really"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruUe4bjTbA0V"
      },
      "outputs": [],
      "source": [
        "# save the model with min val_loss\n",
        "file_path = \"/content/drive/MyDrive/SRCNN/saved_model/srcnn3.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvO9P50bcwiv"
      },
      "outputs": [],
      "source": [
        "m.fit(\n",
        "    train,\n",
        "    epochs = 800,\n",
        "    validation_data = val,\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor = 'val_loss', patience=5),\n",
        "        checkpoint,]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCobJTwk2n7_"
      },
      "source": [
        "### Test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQMgPVxpd8up"
      },
      "outputs": [],
      "source": [
        "def merge(path_ori, srcnn, scale):\n",
        "    img_arr = np.array(Image.open(path_ori), dtype=np.uint8)\n",
        "    img_arr = np.array(cv2.cvtColor(np.array(img_arr), cv2.COLOR_RGB2YCrCb), dtype=float)\n",
        "    y_channel = img_arr[:,:,0]\n",
        "    img_ori = tf.expand_dims(crop(y_channel, scale), axis=-1)\n",
        "    h, w, _ = img_ori.shape\n",
        "\n",
        "    down_sample = tf.image.resize(img_ori, (int(h/scale), int(w/scale)), method='bicubic')\n",
        "\n",
        "    img_input = tf.image.resize(down_sample, (h, w), method='bicubic')\n",
        "    patches = []\n",
        "    col = 0\n",
        "    for x in range(0, h-SIZE_INPUT+1, SIZE_LABEL):\n",
        "        row = 0\n",
        "        for y in range(0, w-SIZE_INPUT+1, SIZE_LABEL):\n",
        "            sub_img_input = img_input[x:x+SIZE_INPUT, y:y+SIZE_INPUT]\n",
        "            patches.append(sub_img_input)\n",
        "            row += 1\n",
        "        col += 1\n",
        "    img_in = tf.convert_to_tensor(patches)\n",
        "\n",
        "    res = srcnn.predict(img_in)\n",
        "    img_sr = np.zeros((col*SIZE_LABEL, row*SIZE_LABEL, 1))\n",
        "    print(img_sr.shape)\n",
        "    for i in range(len(res)):\n",
        "        r = i % row\n",
        "        c = i // row\n",
        "        img_sr[c*SIZE_LABEL:(c+1)*SIZE_LABEL, r*SIZE_LABEL:(r+1)*SIZE_LABEL, :] = res[i]\n",
        "\n",
        "    return img_ori, img_input, img_sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9-_xXGfCa6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}